{"cells":[{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":328,"status":"ok","timestamp":1738277795336,"user":{"displayName":"高珩","userId":"08823366031994207764"},"user_tz":360},"id":"NqD9Na21fnjL"},"outputs":[],"source":["# imports\n","import os\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import BatchNormalization, Input\n","\n","from matplotlib import pyplot as plt\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_curve, auc\n","from tensorflow.keras.layers import Layer\n","from scipy.signal import correlate\n","sample_rate = 4096   # or your actual sampling rate\n","max_lag_ms = 10      # ±10 ms"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1738277795715,"user":{"displayName":"高珩","userId":"08823366031994207764"},"user_tz":360},"id":"Etb_1bMBIs4p"},"outputs":[],"source":["import random\n","random.seed(42)\n","np.random.seed(42)\n","tf.random.set_seed(42)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1371,"status":"ok","timestamp":1738277797084,"user":{"displayName":"高珩","userId":"08823366031994207764"},"user_tz":360},"id":"LQ19uPwXf8kt","outputId":"b08bc4f9-e85b-4e37-f2a9-fab33e4ce64a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir('/content/drive/My Drive/LIGO/Datasets')"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1738277797084,"user":{"displayName":"高珩","userId":"08823366031994207764"},"user_tz":360},"id":"EiaaSFBofnjP"},"outputs":[],"source":["# # load data and normalize it\n","# background = np.load('background.npz')['data']\n","# stds = np.std(background, axis=-1)[:, :, np.newaxis]\n","# background = background/stds\n","# background = np.swapaxes(background, 1, 2)\n","\n","# bbh = np.load('bbh_for_challenge.npy')\n","# stds = np.std(bbh, axis=-1)[:, :, np.newaxis]\n","# bbh = bbh/stds\n","# bbh = np.swapaxes(bbh, 1, 2)\n","\n","# sglf = np.load('sglf_for_challenge.npy')\n","# stds = np.std(sglf, axis=-1)[:, :, np.newaxis]\n","# sglf = sglf/stds\n","# sglf = np.swapaxes(sglf, 1, 2)\n","# # Create train and test datasets\n","# x_train, x_test, y_train, y_test = train_test_split(\n","#      background, background, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":11643,"status":"ok","timestamp":1738277808725,"user":{"displayName":"高珩","userId":"08823366031994207764"},"user_tz":360},"id":"BRpdaUlabV7H"},"outputs":[],"source":["# load data and normalize it\n","# didnt swap axes, new shape is (100000, 2, 200)\n","background = np.load('background.npz')['data']\n","bbh = np.load('bbh_for_challenge.npy')\n","sglf = np.load('sglf_for_challenge.npy')\n","\n","def correlation_feature(x):\n","    data = np.empty((1000,1,200))\n","    for i, signal in enumerate(x):\n","        s1 = signal[0]\n","        s2 = signal[1]\n","        correlated = correlate(s1, s2, mode='full', method='auto')[::2]\n","        data[i]=correlated\n","    x = np.concatenate((x,data),axis = 1)\n","    stds = np.std(x,axis=-1)[:,:,np.newaxis]\n","    x = x/stds\n","    x = np.swapaxes(x,1,2)\n","    return x\n","\n","background = correlation_feature(background)\n","bbh = correlation_feature(bbh)\n","sglf = correlation_feature(sglf)\n","\n","# Create train and test datasets\n","x_train, x_test, y_train, y_test = train_test_split(\n","     background, background, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"nSS8Jm0_fnjR"},"source":["SOLUTION"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1584981,"status":"ok","timestamp":1738279393703,"user":{"displayName":"高珩","userId":"08823366031994207764"},"user_tz":360},"id":"Gdzk8vpMfnjS","outputId":"7f10b5ac-c9d5-4591-fe1f-125ac7952640"},"outputs":[],"source":["class RotaryPositionEmbedding(Layer):\n","    def call(self, x):\n","        batch_size = tf.shape(x)[0]\n","        seq_len = tf.shape(x)[1]\n","        dim_head = tf.shape(x)[2]\n","        half_dim = dim_head // 2\n","\n","        # Compute frequencies and angles\n","        frequency = tf.exp(-tf.range(half_dim, dtype=tf.float32) / tf.cast(half_dim, tf.float32) * tf.math.log(10000.0))\n","        pos = tf.range(seq_len, dtype=tf.float32)\n","        angles = tf.einsum(\"i,j->ij\", pos, frequency)\n","\n","        # Create sin/cos embeddings\n","        sin_embed = tf.sin(angles)\n","        cos_embed = tf.cos(angles)\n","\n","        # Reshape for broadcasting\n","        sin_embed = tf.reshape(sin_embed, [1, seq_len, half_dim])\n","        cos_embed = tf.reshape(cos_embed, [1, seq_len, half_dim])\n","\n","        # Split into even/odd components\n","        x_reshaped = tf.reshape(x, [batch_size, seq_len, half_dim, 2])\n","        x_cos = x_reshaped[:, :, :, 0]\n","        x_sin = x_reshaped[:, :, :, 1]\n","\n","        # Apply rotation\n","        rotated_even = x_cos * cos_embed - x_sin * sin_embed\n","        rotated_odd = x_sin * cos_embed + x_cos * sin_embed\n","\n","        # Interleave and reshape back\n","        x_rotated = tf.reshape(\n","            tf.stack([rotated_even, rotated_odd], axis=-1),\n","            [batch_size, seq_len, dim_head]\n","        )\n","\n","        return x_rotated\n","\n","class Model:\n","    def __init__(self):\n","        super().__init__()\n","\n","    # def positional_encoding(self, inputs):\n","    #     embed_size = inputs.shape[-1]\n","    #     input_length = inputs.shape[-2]\n","    #     assert embed_size % 2 == 0, 'embed_size must be even'\n","    #     p, i = np.meshgrid(np.arange(input_length), np.arange(embed_size // 2))\n","    #     pos_emb = np.empty((1,input_length, embed_size))\n","    #     pos_emb[0,:,::2] = np.sin(p/(10000**(i/embed_size))).T\n","    #     pos_emb[0,:,1::2] = np.cos(p/(10000**(i/embed_size))).T\n","    #     self.pos_encoding = tf.constant(pos_emb.astype(np.float32))\n","    #     return inputs + self.pos_encoding[:, :input_length, :]\n","\n","\n","    def transformer_encoder(self, inputs, head_size, num_heads, ff_dim, dropout, bottleneck_dim = 32):\n","        x = layers.Conv1D(filters=ff_dim, kernel_size=3, dilation_rate=5, padding='same', activation='relu')(inputs)\n","        x = layers.Dropout(dropout)(x)\n","\n","        x = layers.MultiHeadAttention(\n","            key_dim=head_size, num_heads=num_heads, dropout=dropout\n","        )(inputs, inputs)\n","        x = layers.Dropout(dropout)(x)\n","        x = layers.LayerNormalization(epsilon=1e-6)(x)\n","        # x = BatchNormalization(epsilon=1e-6)(x)\n","        res = x + inputs\n","\n","        # x = layers.Conv1D(filters=ff_dim, kernel_size=15,padding='same', activation=\"relu\")(res)\n","        x = layers.Conv1D(filters=ff_dim, kernel_size=15, dilation_rate=1, padding='same', activation='relu')(res)\n","        x = layers.Dropout(dropout)(x)\n","        # x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=15,padding='same')(x)\n","        x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=15, dilation_rate=1, padding='same')(x)\n","        x = layers.LayerNormalization(epsilon=1e-6)(x)\n","        # x = BatchNormalization(epsilon=1e-6)(x)\n","        return x + res\n","\n","    def dense_decoder(self, inputs, ff_dim, output_dim, dropout):\n","        # Flatten the input to apply dense layers\n","        x = layers.Flatten()(inputs)\n","        x = layers.Dense(ff_dim, activation=\"relu\")(x)\n","        x = layers.Dropout(dropout)(x)\n","        x = layers.LayerNormalization(epsilon=1e-6)(x)\n","        res = layers.Dense(ff_dim)(x)  # Align dimensions for residual\n","\n","        x = layers.Dense(ff_dim, activation=\"relu\")(x)\n","        x = layers.Dropout(dropout)(x)\n","        x = layers.Dense(np.prod(inputs.shape[1:]))(x)  \n","        x = layers.LayerNormalization(epsilon=1e-6)(x)\n","\n","        # Reshape back to original input shape\n","        x = layers.Reshape(inputs.shape[1:])(x)\n","        return x + inputs  # Adding input directly, assuming output_dim matches inputs shape[-1]\n","\n","\n","    def build_model(self, input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, num_dense_blocks, dropout):\n","        inputs = keras.Input(shape=input_shape)\n","        inputs = RotaryPositionEmbedding()(inputs)\n","        # Encoder\n","        x = inputs\n","        for _ in range(num_transformer_blocks):\n","            x = self.transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n","        encoder_output = x\n","        # Decoder\n","        x = encoder_output\n","        for _ in range(num_dense_blocks):\n","            x = self.dense_decoder(x, ff_dim, input_shape[-1], dropout)\n","        # Output layer\n","        outputs = layers.Dense(input_shape[-1])(x)\n","        self.ae = keras.Model(inputs, outputs)\n","        self.ae.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(learning_rate=5e-5))\n","\n","    def predict(self, X, batch_size=32):\n","        return np.mean((self.ae.predict(X, batch_size=batch_size) - X) ** 2, axis=(1,2))\n","\n","    def __call__(self, inputs, batch_size=64):\n","        return self.ae.predict(inputs, batch_size=batch_size)\n","\n","    def save(self, path):\n","        self.ae.save(path)\n","\n","    def load(self):\n","        self.ae = keras.models.load_model(os.path.join(os.path.dirname(__file__), 'model.keras'))\n","\n","    def fit(self, x_train, **kwargs):\n","        history = self.ae.fit(x_train, x_train, **kwargs)\n","        return history\n","\n","# Example usage:\n","input_shape = x_train.shape[1:]\n","head_size = 80\n","num_heads = 2\n","ff_dim = 80\n","num_transformer_blocks = 4\n","num_dense_blocks = 2\n","dropout = 0.2\n","\n","# build the model\n","autoencoder = Model()\n","autoencoder.build_model(\n","    input_shape=input_shape,\n","    head_size=head_size,\n","    num_heads=num_heads,\n","    ff_dim=ff_dim,\n","    num_transformer_blocks=num_transformer_blocks,\n","    num_dense_blocks=num_dense_blocks,\n","    dropout=dropout\n",")\n","\n","# Assuming x_train is your input data\n","history = autoencoder.fit(\n","    x_train, # For autoencoders, input is same as output\n","    validation_split=0.2,\n","    epochs=50,\n","    batch_size=90,\n","    callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":476},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1738279393703,"user":{"displayName":"高珩","userId":"08823366031994207764"},"user_tz":360},"id":"X6YvtMUPfnjT","outputId":"d4e0385c-8401-4d93-bec9-b3f0abd4b289"},"outputs":[],"source":["# This is just an example; you would probably like to train the model for more epochs\n","metric = \"loss\"\n","plt.figure()\n","plt.plot(history.history[metric])\n","plt.plot(history.history[\"val_\" + metric])\n","plt.title(\"Model \" + metric)\n","plt.ylabel(metric, fontsize=\"large\")\n","plt.xlabel(\"epoch\", fontsize=\"large\")\n","plt.legend([\"train\", \"val\"], loc=\"best\")\n","plt.show()\n","plt.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":523},"executionInfo":{"elapsed":10132,"status":"ok","timestamp":1738279403830,"user":{"displayName":"高珩","userId":"08823366031994207764"},"user_tz":360},"id":"RXJOTDoNfnjT","outputId":"d81c30c0-4bae-4046-c019-49210d3740e9"},"outputs":[],"source":["def make_plot_roc_curves(qcd, bsm):\n","\n","    true_val = np.concatenate((np.ones(bsm.shape[0]), np.zeros(qcd.shape[0])))\n","    pred_val = np.concatenate((bsm, qcd))\n","\n","    fpr_loss, tpr_loss, threshold_loss = roc_curve(true_val, pred_val)\n","\n","    auc_loss = auc(fpr_loss, tpr_loss)\n","\n","    qcd[::-1].sort()\n","\n","    plt.plot(fpr_loss, tpr_loss, '-', label=f'MSE (auc = %.1f%%)'%(auc_loss*100.),\n","        linewidth=1.5)\n","    plt.plot(np.linspace(0, 1),np.linspace(0, 1), '--', color='0.75')\n","    plt.ylabel('True Positive Rate')\n","    plt.xlabel('False Positive Rate')\n","    plt.grid(True)\n","    plt.legend()\n","    plt.tight_layout()\n","    plt.show()\n","    return auc_loss\n","\n","# evaluate on test background and signal samples\n","background_test = autoencoder.predict(x_test)\n","signal_test = autoencoder.predict(bbh[:20000])\n","\n","AUC_bbh=make_plot_roc_curves(background_test,signal_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"executionInfo":{"elapsed":639,"status":"ok","timestamp":1738279404465,"user":{"displayName":"高珩","userId":"08823366031994207764"},"user_tz":360},"id":"WKgxLjZYfnjU","outputId":"8c9a514c-6434-4c33-ac93-7890c6e12add"},"outputs":[],"source":["plt.hist(background_test, density=True, bins=100, alpha=0.5, label='Background')\n","plt.hist(signal_test, density=True, bins=100, alpha=0.5, label='Signal')\n","plt.semilogy()\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"executionInfo":{"elapsed":3692,"status":"ok","timestamp":1738279408155,"user":{"displayName":"高珩","userId":"08823366031994207764"},"user_tz":360},"id":"VcH6isD9spLC","outputId":"136a07c8-f40b-4a16-9305-63b00041a459"},"outputs":[],"source":["signal_test = autoencoder.predict(sglf[:20000])\n","\n","AUC_sg=make_plot_roc_curves(background_test,signal_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"executionInfo":{"elapsed":593,"status":"ok","timestamp":1738279408745,"user":{"displayName":"高珩","userId":"08823366031994207764"},"user_tz":360},"id":"bZGkU0Mz7lmZ","outputId":"08e97a49-162b-4a9e-83f9-725bfd6a9524"},"outputs":[],"source":["plt.hist(background_test, density=True, bins=100, alpha=0.5, label='Background')\n","plt.hist(signal_test, density=True, bins=100, alpha=0.5, label='Signal')\n","plt.semilogy()\n","plt.legend()"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":271,"status":"ok","timestamp":1738279409013,"user":{"displayName":"高珩","userId":"08823366031994207764"},"user_tz":360},"id":"4X1E3dEVBdQe"},"outputs":[],"source":["formatted_scoreA = f\"{AUC_bbh * 100:.1f}\"  \n","formatted_scoreB = f\"{AUC_sg * 100:.1f}\"  \n","\n","# Combine the scores into the filename format\n","combined_scores = f\"({formatted_scoreA})({formatted_scoreB})\"\n","\n","# Save the model with the combined scores in the filename\n","save_path = f\"/content/drive/My Drive/LIGO/Datasets/TransformerHDR_model/model_{combined_scores}.keras\"\n","autoencoder.save(save_path)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"}},"nbformat":4,"nbformat_minor":0}
